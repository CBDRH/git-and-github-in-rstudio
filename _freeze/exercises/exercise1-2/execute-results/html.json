{
  "hash": "704bf8080510f75f407755d57a4d84d2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Step-by-step guide\"\nformat: \n  html:\n    execute:\n      echo: true\n      eval: false \nnumber-sections: true      \n---\n\n\n# Set up your code file meta data\n\nIt's good practice to include some code file meta information in the form of commented text at the top of every code file. This information is to help orientate you to what you were trying to do with this code when you come back to it in the future.\n\n1. In RStudio, open the file `exercises/1-code/1-clean-self-assessed-health.R`\n2. Update the details in the title box. You can edit this to include what you like. Standard items to list include: \n    - A project name and purpose\n    - The input file (here `exercises/2-raw-data/national-health-survey-2022-table-2.xlsx`)\n    - Any outputs that the code generates (here the output file will be the cleaned data saved in `exercises/3-clean-data/vis1.Rda`)\n    - Code author names\n\nI tend not to include the date because, assuming you work on the code over time, dates are better captured in Git commits.  \n\n<hr>\n\n\n# Load libraries\n\nIt is good practice to load all the libraries you need in a script in one place at the top of the file. \n\nWe will use three libraries to load and clean the ABS data: \n\n1. `readxl` to read the raw `.xlsx` file into R\n1. `dplyr` for data manipulation \n1. `tidyr` to pivot the data from wide to long\n\nGo ahead and load all three libraries by adding `library()` calls to your script, as below. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Load libraries\nlibrary(readxl) \nlibrary(dplyr) \nlibrary(tidyr) \n```\n:::\n\n\n::: {.aside} \n\nNote that you don't need to wrap the package name in quotation marks when loading the package.\n\n:::\n\n<hr>\n\n# Commit your changes\n\nStart as you mean to go on and commit your changes to git, then push these to your repo on GitHub.\n\n1. Make sure to save your changes to the code file\n2. In the git panel, tick the box next to `exercises/1-code/clean-self-assessed-health.R` @Aarathy\n\n::: {.aside}\n![In the Git panel tick the box then slect commit](../images/screenshot-placeholder.png)\n:::\n\n3. Select Commit\n4. Write a short commit message in the box @Aarathy\n\n::: {.aside}\n![Write a short commit message then click Push](../images/screenshot-placeholder.png)\n:::\n\n5. Click Push\n\n\n::: {.callout-tip}\n\n## How often to commit?\n\nCommit and push as often as you like! In practice you might find you commit less often near the start of a project, but as he project is close to completion you commit every new change. As you get used to the workflow you will get better at committing discrete, conceptually related changes to your code base.\n\n:::\n\n::: {.callout-caution}\n\n## Checkpoint\n\nIf you open your GitHub repo in a browser, you should see your recent commit as the latest update. \n\n:::\n\n<hr>\n\n# Download the data locally\n\nWith R, it is easy to automate the process of downloading the NHS  data directly; no manual point-and-click needed.\n\n1. Assign the download string to `myURL`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Spreadsheet url\nmyURL <- \"https://www.abs.gov.au/statistics/health/health-conditions-and-risks/national-health-survey/2022/NHSDC02.xlsx\"\n```\n:::\n\n    \n\n2. Download the file using `download.file()` function\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Download the file locally\ndownload.file(url = myURL,\n              destfile = 'exercises/2-raw-data/national-health-survey-2022-table-2.xlsx')\n```\n:::\n\n\n::: {.aside}\n\nThe `destfile` argument indicates the file path where the downloaded file is to be saved. Note that it is a relative file path, because you are working in an R project environment.\n\n:::\n\n::: {.callout-caution}\n\n## Checkpoint\nIf you have run this code successfully, the file `national-health-survey-2022-table-2.xlsx` should be saved in your `exercises/2-raw-data` folder. Go ahead and open it---you can do so from within R Studio by going to the **Files** tab, clicking on the file name and selecting **View File**. @Aarathy\n\n:::\n\n::: {.aside}\n\n![Open the downloaded `.xlsx` file from the Files tab ](../images/screenshot-placeholder.png)\n\n:::\n\n<hr> \n\n# Read in the data to R\n\nWe now have the raw `.xlsx` file in our project folder. To open the file in R we can use the `read_excel()` function from the `readxl` package. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read in the raw data\ndf1Raw <- read_excel(\n            path = 'exercises/2-raw-data/national-health-survey-2022-table-2.xlsx',\n            sheet = 'Table 2.3_Proportions',\n            skip = 5,\n            .name_repair = ~ make.names(.x, unique = TRUE)\n          )\n```\n:::\n\n\nThere are a few important arguments we need to specify:\n\n* `path` The path to where you downloaded the `.xlsx` file **raw-data/national-health-survey-2022-table-2.xlsx**\n* `sheet` The sheet to read. Here we want to access the data as percentages so we read the sheet **Table 2.3_Proportions**\n* `skip` Notice in the `.xlsx` file, the first row of useful data (the state names) is on row six. Setting `skip = 5` ensures that the data read starts from row six. The default behaviour is for the variable names to be taken from the first row so the state names become the variable names!\n* `.name_repair` This allows us specify a method to repair the default column names. In particular, because the state names are duplicated, the function `make.names(unique=TRUE)` ensures they are unique by appending `.1` to duplicated names. Thus we have variables `NSW` and `NSW.1`, `Qld` and `Qld.1` etc. \n\n::: {.aside}\n\nIn the line of code `.name_repair = ~ make.names(.x, unique = TRUE)` the `~` (tilde) expression is a shorthand for defining a function. `.x` is a placeholder for the argument passed to the function, which in this case represents the names of the columns that need to be repaired. So `~ make.names(.x, unique = TRUE)` is is equivalent to the function\n\n::: {.cell}\n\n```{.r .cell-code}\nfunction(.x) {\n  make.names(.x, unique = TRUE)\n}\n```\n:::\n\n\nTo get a feel for what this is doing, try entering the following code snippet at the console: `make.names(c('Mark', 'Mark'), unique = TRUE)`\n\n:::\n\n::: {.callout-caution}\n\n## Checkpoint\n\nAll going smoothly, you now have the raw data in your local R environment. You can examine it by clicking on the `df1Raw` dataframe in the Environment tab. This is a good start but we are still a long way from tidy data!\n\n:::\n\nNotice that the first column (named `X` because it was blank in the raw file) has many different categories corresponding to the first column of the `xlsx` file. We only want the categories relating to self-assessed health, so filtering them out is the next step.\n\n::: {.aside}\n![View the `df1Raw` dataframe in the Environment tab](../images/screenshot-placeholder.png)\n:::\n\n<br>\n\n# Filter to the self-assessed health categories\n\nAt this point, the dataset `df1Raw` dataset has 118 rows, but we only need the five rows relating to the five self-assessed health categories: Excellent, Very Good, Good, Fair, and Poor.\n\nTo filter these rows, we can define a vector with these category names and then use the filter function. We don't want to edit our raw dataframe, so we will assign the result to a new dataframe `df1Clean`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define health status categories\nhealthStatus <- c(\"Poor\", \"Fair\", \"Good\", \"Very good\", \"Excellent\")\n\n# Filter to these rows\ndf1Clean <- df1Raw |>\n  filter(X %in% healthStatus)\n```\n:::\n\n\n::: {.aside}\nIn R, the `%in%` operator is used to check if elements of one vector are contained in another vector. Try entering `'Ringo' %in% c('John', 'Paul', 'George', 'Ringo')` at the console.\n:::\n\n\n::: {.callout-caution}\n\n## Checkpoint\nAt this point, `df1Clean` should have 5 observations and 19 variables. You can confirm this by entering `dim(df1Clean)` at the console.\n\n:::\n\n<hr>\n\n# Select the columns of interest\n\nThe original dataset provides proportions and age-standardised proportions. We just need the age-standardised proportions, so the next step is to select the variables of interest. Because the age-standardised data came second, these are the variables named `NSW.1`, `Qld.1` etc. We can select these using `select()` and the convenience function `ends_with()` as follows. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Append this line to the previous code using |>\nselect(c(X, ends_with(\".1\"), -'Australia.1'))\n```\n:::\n\n\n::: {.aside}\n\nSo when you append this line your updated code chunk will be\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter to these rows\ndf1Clean <- df1Raw |>\n  filter(X %in% healthStatus) |> \n  select(c(X, ends_with(\".1\"), -'Australia.1'))\n```\n:::\n\n\n\nAs you work through the sections below keep adding the code lines like this! \n<br><br>\nNote that the code `select(c(X, ends_with(\".1\"), -'Australia.1'))` says we want to keep (i) the column `X`, (ii) every column ending in `.1` but (iii) _not_ the column `Australia.1`. \n\n:::\n\n::: {.callout-caution}\n\n## Checkpoint\nAt this point, `df1Clean` should have 5 observations and 9 variables. You can confirm this by entering `dim(df1Clean)` at the console.\n\n:::\n\n<hr>\n\n# Pivot from wide format to long format\n\nIf you examine the `df1Clean` data as it currently stands, there are five rows, one each for each category of health status, and nine columns, the health status plus eight states and territories. \n\nTo transform to a tidy dataset we need to move from this **wide** format to a **long** format with one variable indicating state, one variable indicating health status and one variable indicating percentage. To do this, we will use the `pivot_longer()` function from the `tidyr` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Append this line to the previous code using |>\npivot_longer(\n  cols = ends_with(\".1\"),\n  names_to = 'state',\n  values_to = 'percent') \n```\n:::\n\n\nThere are three arguments to the `pivot_longer()` function here:\n\n* `cols` defines the columns to pivot into longer format. We can choose the eight columns corresponding to the states and territories by using the `ends_with()` convenience function.\n* `names_to` specifies the name for the new column to create from the information stored in the column names of data specified by `cols`.  \n* `values_to` is the name of the column to create from the data stored in cell values.\n\n::: {.callout-caution}\n\n## Checkpoint\n\nAt this point, `df1Clean` should have 40 observations and 3 variables. You can confirm this by entering `dim(df1Clean)` at the console. Check the names by entering `names(df1Clean)` at the console; it should return `X`, `state`, and `percent`. \n:::\n\n<hr>\n\n# Rename the variable `X`\n\n`X` isn't a very informative variable name so let's rename it to something more descriptive using the `rename()` function. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Append this line to the previous code using |>\nrename(status = X)\n```\n:::\n\n\n::: {.aside}\nRemember the syntax is `rename(newName = oldName)`\n:::\n\n<hr>\n\n# Tidy up the `state` variable\n\nThe `state` variable is in an awful state. First of all, the state names still have the `.1` suffix (NSW.1 etc). Secondly, it is a character vector, but for plotting purposes its going to be better to have this as a factor variable. We can create a better version of the `state` variable using `mutate()`, combined with `as.factor()` to make our new variable a factor variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Append this code to the previous code using |>\nmutate(\n    state = factor(\n      case_when (\n        state == 'NSW.1' ~ 'New South Wales',\n        state == 'Vic..1' ~ 'Victoria',\n        state == 'Qld.1' ~ 'Queensland',\n        state == 'SA.1' ~ 'South Australia',\n        state == 'WA.1' ~ 'Western Australia',\n        state == 'Tas..1' ~ 'Tasmania',\n        state == 'NT.1' ~ 'Northern Territory',\n        state == 'ACT.1' ~ 'Australian Capital Territory'\n      ))) \n```\n:::\n\n\n::: {.aside}\n\nNote that we overwrote the original `state` variable with a new version. Here it is okay because we are using code to create a new dataset leaving the original intact, but obviously you should never overwrite variables in the canonical version of your data!\n\n:::\n\n::: {.callout-caution}\n\n## Checkpoint\n\nYou can confirm that the new `state` variable is a factor variable by entering `is.factor(df1Clean$state)` at the console. You can also confirm the levels of the new factor variable by entering `levels(df1Clean$state)`. Note that because we didn't specify any levels, they are ordered alphabetically by default.\n:::\n\n<hr>\n\n\n# Tidy up the `status` variable\n\nThings are looking good now! One additional change is that it will be useful later to code the `status` variable as a factor. We can do that with another call to `mutate()`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Append this code to the previous code using |>\nstatus = factor(status, levels = healthStatus)\n```\n:::\n\n\nHere we have also set the `levels` option to `healthStatus` which we defined way back in Step 6 as the vector `c(\"Poor\", \"Fair\", \"Good\", \"Very good\", \"Excellent\")`. This ensures that when we plot the data the categories will have a sensible sorting from **Poor** health to **Excellent** health. If we didn't do this they would default to being sorted alphabetically and appear on the plot in the wrong order (**Excellent** to **Very good**).\n\n::: {.aside}\n\nHere we have separated the steps of coding `state` and `status` as factor variables into two separated calls to `mutate()`. It is also possible to create multiple variables in a single `mutate()` call so Steps 9 and 10 could be completed in a single step as\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  mutate(\n    state = factor(\n      case_when (\n        state == 'NSW.1' ~ 'New South Wales',\n        state == 'Vic..1' ~ 'Victoria',\n        state == 'Qld.1' ~ 'Queensland',\n        state == 'SA.1' ~ 'South Australia',\n        state == 'WA.1' ~ 'Western Australia',\n        state == 'Tas..1' ~ 'Tasmania',\n        state == 'NT.1' ~ 'Northern Territory',\n        state == 'ACT.1' ~ 'Australian Capital Territory'\n      )),\n    status = factor(status, levels = healthStatus)\n  )\n```\n:::\n\n\n\n:::\n\n::: {.callout-caution}\n\n## Checkpoint\n\nYou can confirm that the new `status` variable is a factor variable by entering `is.factor(df1Clean$status)` at the console. You can also confirm the levels of the new factor variable by entering `levels(df1Clean$status)`. The category levels should appear in increasing order from **Poor** to **Excellent**, not alphabetically.\n:::\n\n<hr>\n\n# Sort the data\n\nWe are done! The dataset is in tidy data format and the categorical variables are nicely coded as factors. Currently the dataset is sorted by `status` first and then by `state`; it is easier to read if sorted by `state`, which we can quickly do with the arrange function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Append this code to the previous code using |>\narrange(state, status)\n```\n:::\n\n\n# Save the clean data\n\nHaving gone to all that effort to clean the data, we definitely want to save it! We will save it in two formats: an R data file `.Rda` for working in R and a plain old `.csv` which is a good option if you want to share the data underlying your chart with non-R users.\n\nAdd the following blocks of code to your script to save the `df1Clean` file in your `exercises/3-clean-data` folder.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save the data in .Rda format\nsave(df1Clean, file=here::here('exercises/3-clean-data/vis1.Rda'))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save the data in .csv format\nwrite.csv(df1Clean,\n          file=here::here('exercises/3-clean-data/vis1.csv'),\n          row.names = FALSE)\n```\n:::\n\n\n::: {.aside}\n\nNote we are using the `here()` function from the `here` package to determine the root folder of the R project. Try entering `here::here()` at the console to confirm the location is where you expect.\n\n:::\n\n::: {.callout-caution}\n\n## Checkpoint\n\nNow that you've completed your cleaning code, you should test everything runs smoothly. Save your file then restart your R session by clicking on **Session > Restart R**. \n\nHighlight the full R Script (Cmd/Ctrl + A) then run everything that is highlighted (Cmd/Ctrl + Enter). The whole data cleaning pipeline should run and the clean data file should update every time you run this.\n\nLook out for errors in the console: if you left out a step or completed it in interactively in the console and didn't save the code then the code will break. \n\nIf you are happy with everything remember to Git commit and push your code.\n\n:::\n\n<hr>\n\n::: {style=\"margin: 0 auto;\"}\n\nCongratulations, you made it!! \n\n<iframe src=\"https://giphy.com/embed/ely3apij36BJhoZ234\" width=\"480\" height=\"480\" frameBorder=\"0\"></iframe><p><a href=\"https://giphy.com/gifs/good-job-congratulations-otter-ely3apij36BJhoZ234\">via GIPHY</a></p>\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}